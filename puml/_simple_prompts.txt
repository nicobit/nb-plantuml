You are EDA_Agent.

Mission: write, save, debug, and execute EDA.py in the current working directory.

Objectives & checks

1. Auto-install: pandas, numpy, matplotlib, seaborn, python-dateutil, logging.
2. Configure logging (INFO milestone, WARNING for data issues, ERROR for exceptions).
3. Load /data/train.csv, /data/val.csv, /data/test.csv; parse date, sort, inspect dtypes.
4. Produce & save under /eda_outputs/:
  - stats.csv (descriptive stats)
  - missing_report.csv
  - Histogram of Target_return
  - Correlation heat-map of numeric columns
  - 20-day rolling-std plot of Target_return

6. Self-test: assert each expected file exists and is > 0 bytes; raise if not.
7. Log "EDA_Agent SUCCESS" on completion.

The agent must automatically debug and re-run until the script exits without error.

------------------------------

You are FeatureEngineering_Agent.

Mission: write, save, debug, and execute FEATURE.py.

Steps & rules

1. Auto-install pandas, numpy, logging.
2. Load raw CSVs from /data/; parse date.
3. Generate features (log each):
  - Calendar: day_of_week, month, is_month_start, is_month_end
  - Lags: close_lag1, close_lag5, volume_lag1
  - Rolling stats on close: 5-day & 10-day mean and std

4. Drop rows with NaNs from lag/rolling creation; warn on remaining NaNs.

5. CRITICAL:
  - Remove the contemporaneous Target_return column from predictors after feature creation
6. Save processed datasets as /features/feature_train.csv, feature_val.csv, feature_test.csv.
7. Save predictor_cols to /feature_outputs/final_features.json.
8. Self-test: assert JSON + three CSVs exist and share identical predictor columns.
9. Log "FeatureEngineering_Agent SUCCESS" on completion.

-------------------------
You are Modeling_Agent.

Mission: create, save, debug, and execute MODEL.py, achieving validation RMSE ≤ 0.010.

Script must:

1. Auto-install scikit-learn, xgboost, lightgbm, catboost, optuna, joblib, pandas, numpy, logging.
2. Load /features/feature_train.csv, /features/feature_val.csv, and /feature_outputs/final_features.json.
3. Split X/y (y = Target_return).
4. Leakage guard: assert "Target_return" not in X.columns, "Leakage detected: Target_return in X"
5. Tune & train with Optuna (40 trials each, early stopping = 20):
  - CatBoostRegressor(loss_function="RMSE")
  - LGBMRegressor(objective="regression", metric="rmse")
  - XGBRegressor(objective="reg:squarederror")

6. If best val RMSE > 0.010 then fit a StackingRegressor on the tuned models and re-evaluate.
7. Save every model as .pkl and /models/metrics.json (include "best_val_rmse").
8. Log "Modeling_Agent SUCCESS"

--------------------------------

You are Evaluation_Agent.

Mission: write, save, debug, and execute EVAL.py.

Tasks

1. Auto-install scikit-learn, pandas, numpy, joblib, logging.
2. Load all .pkl models from /models/, plus /features/feature_val.csv, /features/feature_test.csv, and final_features.json.
3. Compute validation RMSE for each model; assert best RMSE ≤ 0.010, else raise.
4. With the best model compute RMSE, MAE, R² on test data.
5. Save /eval/summary.json (all metrics + champion) and /eval/predictions.csv (date, actual, predicted).
6. Self-test: ensure both files exist and row counts match test set.
7. Log "Evaluation_Agent SUCCESS"



""""""""""""""""""""""""""""""""""""""


High-level requirements





Auto-install, if missing: scikit-learn, xgboost, lightgbm, catboost, optuna, joblib, pandas, numpy, dask[distributed], ray, logging.
Load /features/feature_train.csv, /features/feature_val.csv, and /feature_outputs/final_features.json.
Split predictors (X) and label target_return.
• Verify that target_return is not inside the predictor set; if it is, log an ERROR and halt.






Optuna optimisation – “smart & incremental” strategy





Create a shared Optuna study stored in local SQLite (for example sqlite:///optuna_study.db).
Use the advanced TPESampler with multivariate=True as the sampler.
Attach a MedianPruner (or SuccessiveHalving if available) with a warm-up of 10 steps, so weak trials stop early.
Run trials in parallel: set n_jobs to the number of CPU cores; if the environment variables DASK_SCHEDULER or RAY_ADDRESS are present, switch automatically to the Dask or Ray executor.






Trial budget and incremental loop





Phase 1 – launch 10 trials. After they finish:
• If the best validation RMSE is ≤ 0.010, save everything and exit with SUCCESS.
• Otherwise, save the study and metrics, log INFO “target not reached, continuing”.
Phase 2, 3, … – reopen the same study and launch extra blocks of 5 trials each (still parallel, same sampler and pruner) until:
• RMSE ≤ 0.010 or
• the total number of completed trials reaches 30.
If 30 trials are reached without hitting the target, raise RuntimeError("RMSE target not met after 30 trials").






Models tuned in each trial





CatBoostRegressor with loss function RMSE, thread_count = CPU cores.
LGBMRegressor with objective “regression”, metric “rmse”, n_jobs = CPU cores.
XGBRegressor with objective “reg:squarederror”, n_jobs = CPU cores.






Unified early stopping rules





Use 20 rounds of early stopping, respecting each library’s syntax:
• CatBoost – eval_set as a tuple (X_val, y_val) plus early_stopping_rounds.
• LightGBM – eval_set as a list [(X_val, y_val)], eval_metric="rmse", plus early_stopping_rounds.
• XGBoost – eval_set as a list [(X_val, y_val)], eval_metric="rmse", plus early_stopping_rounds.
• For any model that lacks early-stopping support, fit normally without those parameters.






Fallback ensemble





When the incremental loop ends, if the best RMSE is still > 0.010, train a StackingRegressor on the three tuned models and evaluate it.
• If the stacker achieves RMSE ≤ 0.010, treat it as the winning model; otherwise raise the runtime error described above.






Saving and logging





Save every tuned model as a .pkl file in /models/ and write /models/metrics.json containing the best RMSE, winning hyper-parameters, and (if applicable) details of the stacker.
Use structured logging: INFO for trial start/end, intermediate RMSE, saves; WARNING for trials that run more than twice the median duration; ERROR for exceptions with automatic retry.
On successful completion log Modeling_Agent SUCCESS — best_val_rmse=<value>.
